{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ChatGroq( api_key = os.environ[\"GROQ_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader\n",
    "documents=SimpleDirectoryReader(\"docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='88b82d74-f995-47c0-8d69-0f558edfa55d', embedding=None, metadata={'page_label': '1', 'file_name': 'Profile.pdf', 'file_path': 'e:\\\\data science\\\\FreeLance_proj\\\\assgin\\\\docs\\\\Profile.pdf', 'file_type': 'application/pdf', 'file_size': 41869, 'creation_date': '2024-05-15', 'last_modified_date': '2023-12-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='\\xa0 \\xa0\\nContact\\nPrafulla Nagar, W.no-12, pin -\\n757001, Baripada, Mayurbhanj,\\nOdisha\\n6371391510  (Mobile)\\nmohantydibyajyoti4@gmail.co\\nm\\nwww.linkedin.com/in/dibyajyoti-\\nmohanty-4a72501b2  (LinkedIn)\\ngithub.com/Dibya069  (Portfolio)\\nTop Skills\\nData Engineering\\nData Pipelines\\nLarge Language Models (LLM)Dibyajyoti Mohanty\\nData Scientist || ML || DL || Computer Vision || Data Analyst || BI\\nDeveloper || PPT Builder\\nMayurbhanj, Odisha, India\\nSummary\\nLove to playing with data and numbers using programming like\\nPython, R, Pandas, NumPy. Also love to visualize the data from\\na different angle by Power BI and presenting that analysis using\\nadvance presentation by Power Point. Also interested in data\\nscience\\nExperience\\nMBH RAW PHARMA\\nMarket Research Analyst\\nApril 2023\\xa0-\\xa0July 2023\\xa0 (4 months)\\nCognizant Softvision\\nProgrammer Analyst Trainee\\nAugust 2022\\xa0-\\xa0February 2023\\xa0 (7 months)\\nIndia\\nStackSystem\\nFrontend Developer\\nSeptember 2020\\xa0-\\xa0March 2021\\xa0 (7 months)\\nBhubaneswar, Orissa, India\\nEducation\\nRavenshaw University\\nUG,\\xa0Computer Science \\xa0·\\xa0(2019\\xa0-\\xa02022)\\n\\xa0 Page 1 of 1', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ec6a19fb-7a43-4fab-8298-904f22da6419', embedding=None, metadata={'page_label': '1', 'file_name': 'res_3.pdf', 'file_path': 'e:\\\\data science\\\\FreeLance_proj\\\\assgin\\\\docs\\\\res_3.pdf', 'file_type': 'application/pdf', 'file_size': 211432, 'creation_date': '2024-05-14', 'last_modified_date': '2023-10-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='DIBYAJYOTI MOHANTY  \\nData Scientist | Data Analyst  |PPT Creator  \\nPassionate data analyst with expertise in Power BI, SQL, Python, and R. Skilled in visualizing complex data and \\nuncovering insights. Interested in Data Science and Machine Learning. Strong pres entation skills and data driven \\nproblem -solving approach. Enthu siastic about exploring possibilities in data scienc e. \\n \\n \\nPython  \\n(Pandas | NumPy  | Matplotlib | Seaborn  | Scikit -Learn  | \\nTensor  Flow | Pytorch  | Ke ras) \\nDeep Learning  \\n(ANN | CNN  |Computer Visi on | YOLO v7) \\n \\nVersion Control Tools  \\n(Git | GitHub  | Gitlab)  \\n \\nNatural Language Processing  (NLP) \\n(RNN | LSTM | GRU  | Bi-LSTM | Transformation | LLM | \\nHugging Face ) \\n \\nData Cleaning  \\n(EDA |ETL | Scaling ) Database  \\n(MYSQL | MongoDB ) \\nData Visu alization  \\n(Power BI | DAX  | Seaborn  |Tableau | Power Point \\n| MS Excel ) \\nMachine Learning  \\n(Decision Tree | Random Forest  | SVM | KNN | PCA \\n| Unsupervised ML ) \\n             \\n            Big Data  \\n(Hadoops |  Spark ) \\n \\n           Soft Skills  \\n(Communication | Presentation  | Teaching ) \\n \\n• Goog le Cloud Big Data and Machi ne Learning Fundamentals  - Link \\n• Data Science Tools by IBM  - Link \\n• Python 101 for Data Science - Link \\n• Google Ad vanced Data Analytics Capstone – Link  \\n• AWS re / start from Tech Mahindra – Link  \\n \\n  \\nMarket Research Analyst , MBH Pharma          2023 Apr – 2023  Jun \\n• Collect & clean the data from all the pharma companies in Goa, Hyderabad & Haryana.  \\n• Used Python for  Data wrapping & Data clean ing and store those in Google  sheet.  \\n \\n \\n \\n \\n \\n \\n \\nGitHub   \\n  \\n Prafulla Nagar, w.no -12, Baripada, Odisha  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e4b1f666-47f5-4dff-818b-eafdce33d850', embedding=None, metadata={'page_label': '2', 'file_name': 'res_3.pdf', 'file_path': 'e:\\\\data science\\\\FreeLance_proj\\\\assgin\\\\docs\\\\res_3.pdf', 'file_type': 'application/pdf', 'file_size': 211432, 'creation_date': '2024-05-14', 'last_modified_date': '2023-10-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=' \\nBreast Cancer Prediction - [Python, Panda, ML, Flask] : \\n• End-to-end project using VS Code, extracting data from MongoDB.  \\n• Achieved  97% accuracy with ensemble ML mode ls. Saved the model as .pkl  for future predictions.  \\n \\n    Revenue Analysis in Hospitality Domain - [MS-Excel, Power BI ]:  •   \\n• Design a Power BI dashboard to analyse  the performance of the hotels. Including Room conditions, capacity, \\nRevenue, performance and time.  \\n• It helps to analyse  the hotel room performance according to different situation and condition  \\n \\nHand Sign  Detection - [Python, Y OLO v7, Computer Vision ]:  •   \\n• Built a model to predict the hand sign gesture  through camera.  \\n• Used Roboflo w for augment the data, an d YOLOv7 model to train that data. At last, create a Flask fr ame work \\nfor user interference  through the model  prediction . Used VS code platform to do this  \\n \\n \\n \\n B.Sc. Infor mation of Science an d Te lecommunication , Ravenshaw University  \\nPassing year – 2022,  80.58 % \\n \\n \\n• Cooking  \\n• Photo graphy  \\n \\n \\n ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9cb005e1-569f-4994-98af-636f61d16843', embedding=None, metadata={'page_label': '1', 'file_name': 'res_4.pdf', 'file_path': 'e:\\\\data science\\\\FreeLance_proj\\\\assgin\\\\docs\\\\res_4.pdf', 'file_type': 'application/pdf', 'file_size': 240496, 'creation_date': '2024-05-14', 'last_modified_date': '2023-10-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='DIBYAJYOTI MOHANTY   \\nData Scientist| Data Analyst |PPT Creator   \\n \\nPassiona te about e xploring the field of data, AI, comp uter vision, D L, ML. Skilled in visualizing complex data and \\nuncovering insights. Interested in Data Science and Machine Learning. Strong presentation skills and data driven \\nproblem -solving approach.  Enthusiastic about exploring  Computer Vision , NLP, Transforms .  \\n \\n  \\nPython   Database   \\n(Pandas | NumPy | Matplotlib | Seaborn | Scikit -Learn |  (MYSQL | MongoDB)  \\nTensor Flow | Pytorch | Keras)  \\nData Visualization  \\nDeep Learning         (Power BI | DAX | Seaborn |Tableau | Power Point  \\n(ANN | CNN |Computer Vision | YOLOv7)     | MS Excel)  \\n  \\nVersion Control Tools   Machine Learning   \\n(Git | GitHub | Gitlab)  (Decision Tree | Random Forest | SVM | KNN | PCA  \\n  | Unsupervised ML)  \\nNatural Language Processing (NLP)                \\n(RNN | LSTM | GRU | Bi -LSTM | Transforms  | LLM |             Big Data   \\nHugging Face)        (Hadoops | Spark)  \\n   \\nData Cleaning             Soft Skills   \\n(EDA |ETL | Scaling)  (Communication | Presentation | Te aching)  \\n  \\n• Google Cloud Big Data and Machine Learning Fundamentals - Link    \\n• Data Science Tools by IBM - Link  \\n• Python 101 for Data Science - Link  \\n• Google Advanced Data Analytics Capstone – Link   \\n• AWS re / start from Tech Mahindra – Link   \\n  \\n  \\nMarket Research Analyst, MBH Pharma              2023 Apr – 2023 Jun  \\n• Collect & clean the data from all the pharma companies in Goa, Hyderabad & Haryana.  \\n• Used Python for Data wrapping & Data cleaning and store those in Google sheet.  \\n  \\n  \\n  \\n  \\nGitHu  \\nb \\n  \\n  \\n   \\n  \\nPra \\nfull \\na Nagar, w.no  \\n- \\n12 \\n, Baripada, Odisha  \\n  \\n  \\n  \\n  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d4ef1c5c-239e-48ad-9189-aefb7e043e55', embedding=None, metadata={'page_label': '2', 'file_name': 'res_4.pdf', 'file_path': 'e:\\\\data science\\\\FreeLance_proj\\\\assgin\\\\docs\\\\res_4.pdf', 'file_type': 'application/pdf', 'file_size': 240496, 'creation_date': '2024-05-14', 'last_modified_date': '2023-10-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='  \\nBreast Cancer Prediction - [Python, Panda, ML, Flask]:  \\n• End-to-end project using VS Code, extracting data from MongoDB.   \\n• Achieved 97% accuracy with ensemble ML models. Saved the model as .pkl for future predictions.  \\n  \\n    Revenue Analysis in Hospitality Domain - [MS-Excel, Power BI]:  •     \\n• Design a Power BI dashboar d to analyse the performance of the hotels. Including Room conditions, capacity, \\nRevenue, performance and time.  \\n• It helps to analyse the hotel room performance according to different situation and condition  \\n  \\nHand Sign Detection - [Python, YOLOv7, Computer Vision]:  • \\n Built a model to predict the hand sign gesture through camera.  \\n• Used Roboflow for augment the data, and YOLOv7 model to train that data. At last, create a Flask frame work \\nfor user interference through the model pr ediction. Used VS code platform to do this  \\n  \\n  \\n  \\n B.Sc. Information of Science and Telecommunication , Ravenshaw University Passing \\nyear – 2022, 80.58 %  \\n  \\n  \\n• Cooking  \\n• Photography  \\n  \\n  \\n  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 5/5 [00:00<00:00, 19.24it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n******\nCould not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nConsider using embed_model='local'.\nVisit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules\n******",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\core\\embeddings\\utils.py:59\u001b[0m, in \u001b[0;36mresolve_embed_model\u001b[1;34m(embed_model, callback_manager)\u001b[0m\n\u001b[0;32m     58\u001b[0m     embed_model \u001b[38;5;241m=\u001b[39m OpenAIEmbedding()\n\u001b[1;32m---> 59\u001b[0m     \u001b[43mvalidate_openai_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\embeddings\\openai\\utils.py:104\u001b[0m, in \u001b[0;36mvalidate_openai_api_key\u001b[1;34m(api_key)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_api_key:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(MISSING_API_KEY_ERROR_MESSAGE)\n",
      "\u001b[1;31mValueError\u001b[0m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\core\\indices\\base.py:145\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[1;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, service_context, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[0;32m    138\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[0;32m    139\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     transformations,\n\u001b[0;32m    141\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    143\u001b[0m )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    146\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    147\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m    148\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[0;32m    149\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    150\u001b[0m     transformations\u001b[38;5;241m=\u001b[39mtransformations,\n\u001b[0;32m    151\u001b[0m     service_context\u001b[38;5;241m=\u001b[39mservice_context,\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    153\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:71\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_async \u001b[38;5;241m=\u001b[39m use_async\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override \u001b[38;5;241m=\u001b[39m store_nodes_override\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     69\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43membed_model_from_settings_or_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     76\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m     77\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39mindex_struct,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     85\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\core\\settings.py:274\u001b[0m, in \u001b[0;36membed_model_from_settings_or_context\u001b[1;34m(settings, context)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39membed_model\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_model\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\core\\settings.py:67\u001b[0m, in \u001b[0;36m_Settings.embed_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the embedding model.\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_embed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\n",
      "File \u001b[1;32mc:\\Users\\dibya\\anaconda3\\envs\\tspace\\lib\\site-packages\\llama_index\\core\\embeddings\\utils.py:66\u001b[0m, in \u001b[0;36mresolve_embed_model\u001b[1;34m(embed_model, callback_manager)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`llama-index-embeddings-openai` package not found, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease run `pip install llama-index-embeddings-openai`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         )\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 66\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load OpenAI embedding model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you intended to use OpenAI, please check your OPENAI_API_KEY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConsider using embed_model=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisit our documentation for more embedding options: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.llamaindex.ai/en/stable/module_guides/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings.html#modules\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# for image multi-modal embeddings\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m embed_model\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: \n******\nCould not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nConsider using embed_model='local'.\nVisit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules\n******"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
