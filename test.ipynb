{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq( api_key = os.environ[\"GROQ_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "GPT = [Free\n",
    "\n",
    "USD $0/month\n",
    "\n",
    "\n",
    "Your current plan\n",
    "Assistance with writing, problem solving and more\n",
    "Access to GPT-3.5\n",
    "Limited access to GPT‑4o\n",
    "Limited access to advanced data analysis, file uploads, vision, web browsing, and custom GPTs\n",
    "Have an existing plan? See billing help\n",
    "Plus\n",
    "\n",
    "USD $20/month\n",
    "\n",
    "\n",
    "Upgrade to Plus\n",
    "Early access to new features\n",
    "Access to GPT-4, GPT‑4o, GPT-3.5\n",
    "Up to 5x more messages for GPT‑4o\n",
    "Access to advanced data analysis, file uploads, vision, and web browsing\n",
    "DALL·E image generation\n",
    "Create and use custom GPTs\n",
    "Limits apply\n",
    "Team\n",
    "\n",
    "USD $25 per person/month*\n",
    "\n",
    "\n",
    "Upgrade to Team\n",
    "Everything in Plus, and:\n",
    "\n",
    "Higher limits for GPT-4, GPT‑4o, and tools like DALL·E image generation, advanced data analysis, web browsing, and more\n",
    "Create and share GPTs with your workspace\n",
    "Admin console for workspace management\n",
    "Team data excluded from training by default. Learn more\n",
    "* Price billed annually, minimum 2 users]\n",
    "\n",
    "Gemini-1.5 = [Pay-as-you-go\n",
    "Rate Limits*#\n",
    "\n",
    "10 RPM (requests per minute)\n",
    "\n",
    "10 million TPM (tokens per minute)\n",
    "\n",
    "2,000 RPD (requests per day)\n",
    "\n",
    "Price (input)\n",
    "\n",
    "$7 / 1 million tokens (preview pricing)\n",
    "\n",
    "Price (output)\n",
    "\n",
    "$21 / 1 million tokens (preview pricing)\n",
    "\n",
    "Prompts/responses used to improve our products\n",
    "\n",
    "No Learn more]\n",
    "\n",
    "DeepGram = [Speech to Text\n",
    "Power your apps with world-class speech recognition in 30+ languages.\n",
    "\n",
    "Includes: Speaker Diarization, Smart formatting, Automatic Language Detection, Deep Search, Keyword Boosting, Multichannel Support, and Callbacks.\n",
    "\n",
    "For detailed model, language, and feature availability, please refer to our Developer Documentation.\n",
    "\n",
    "Pre-Recorded\n",
    "Streaming\n",
    "Model\n",
    "Pay As You Go\n",
    "Growth\n",
    "Enterprise\n",
    "Nova-2\n",
    "$0.0059/min\n",
    "$0.0049/min\n",
    "Nova-1\n",
    "$0.0059/min\n",
    "$0.0049/min\n",
    "Enhanced\n",
    "$0.0165/min\n",
    "$0.0136/min\n",
    "Base\n",
    "$0.0145/min\n",
    "$0.0105/min\n",
    "Custom\n",
    "Redaction\n",
    "$0.0020/min\n",
    "$0.0017/min\n",
    "Text to Speech\n",
    "Responsive, natural-sounding text-to-speech to power your high throughput voicebots and conversational AI applications. Billed per character.\n",
    "\n",
    "Model\n",
    "Pay As You Go\n",
    "Growth\n",
    "Enterprise\n",
    "Aura\n",
    "$0.0150/1k characters\n",
    "$0.0135/1k characters\n",
    "Audio Intelligence\n",
    "Powered by task-specific language models.  \n",
    "Works with or without transcription. Handles text or audio.\n",
    "\n",
    "Model\n",
    "Pay As You Go\n",
    "Growth\n",
    "Enterprise\n",
    "Summarization\n",
    "$0.0003/1k input tokens - $0.0006/1k output tokens\n",
    "$0.00024/1k input tokens - $0.00048/1k output tokens\n",
    "Topic Detection\n",
    "Sentiment Analysis\n",
    "Intent Recognition]\n",
    "\n",
    "LemonFox.ai = [Billing\n",
    "$5 / month\n",
    "\n",
    "Includes 10 million credits:\n",
    "\n",
    "10 million Zephyr chat tokens\n",
    "or 6 million Mixtral tokens\n",
    "or 1,000 images\n",
    "or 30 hours speech-to-text\n",
    "$0.50\n",
    "\n",
    "per additional 1 million credits:\n",
    "\n",
    "1 million Zephyr chat tokens\n",
    "or 600k Mixtral tokens\n",
    "or 100 images\n",
    "or 3 hours speech-to-text]\n",
    "\n",
    "Groq = [Model\tCurrent Speed\tPrice per 1M Tokens (Input/Output)\n",
    "Llama 3 70B (8K Context Length)\t~300 tokens/s\t$0.59/$0.79\n",
    "Mixtral 8x7B SMoE (32K Context Length)\t~480 tokens/s\t$0.27/$0.27\n",
    "Llama 3 8B (8K Context Length)\t~870 tokens/s\t$0.05/$0.10\n",
    "Gemma 7B (8K Context Length)\t~820 tokens/s\t$0.10/$0.10]\n",
    "\"\"\"\n",
    "inp = \"You have given the price rates for different website by using there products. Some operations are same and some are different. Your task is to take all these data and make a excel sheet where any one can understand the rate limt simple looking once. And also so which platform give the lowest and best service for which operation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_res(prompt, inp):\n",
    "    res = client.chat.completions.create(\n",
    "        messages= [\n",
    "                {\"role\": \"system\", \"content\": prompt}, \n",
    "                {\"role\": \"user\", \"content\": inp}\n",
    "            ], \n",
    "            model=\"llama3-8b-8192\"\n",
    "        )\n",
    "    return res.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the provided data, I have created an Excel sheet to summarize the pricing rates for each platform. Here is a concise and organized summary:\n",
      "\n",
      "**Text-to-Text Models**\n",
      "\n",
      "| Platform | Price per 1M Tokens (Input/Output) |\n",
      "| --- | --- |\n",
      "| GPT | $0/month (Free), $20/month (Plus) |\n",
      "| Gemini-1.5 | $7 (input), $21 (output) per 1M tokens |\n",
      "| Groq | Llama 3 70B: $0.59/$0.79, Llama 3 8B: $0.05/$0.10, Gemma 7B: $0.10/$0.10 |\n",
      "| LemonFox.ai | $5/month (10M credits), $0.50 per additional 1M credits |\n",
      "\n",
      "**Speech-to-Text Models**\n",
      "\n",
      "| Platform | Price per Minute |\n",
      "| --- | --- |\n",
      "| DeepGram | Nova-2: $0.0059/min, Nova-1: $0.0059/min, Enhanced: $0.0165/min, Base: $0.0145/min, Custom Redaction: $0.0020/min |\n",
      "\n",
      "**Text-to-Speech Models**\n",
      "\n",
      "| Platform | Price per 1k Characters |\n",
      "| --- | --- |\n",
      "| DeepGram | Aura: $0.0150/1k characters (Pay As You Go), $0.0135/1k characters (Growth/Enterprise) |\n",
      "\n",
      "**Audio Intelligence**\n",
      "\n",
      "| Platform | Price per 1k Input Tokens / Output Tokens |\n",
      "| --- | --- |\n",
      "| DeepGram | Summarization: $0.0003/1k input tokens - $0.0006/1k output tokens, Topic Detection and Sentiment Analysis: not specified |\n",
      "\n",
      "**Lowest and Best Service for Each Operation**\n",
      "\n",
      "* **Text-to-Text Models**: Groq's Llama 3 8B model offers the lowest price at $0.05/$0.10 per 1M tokens (input/output).\n",
      "* **Speech-to-Text Models**: DeepGram's Nova-2 model offers the lowest price at $0.0059/min.\n",
      "* **Text-to-Speech Models**: DeepGram's Aura model offers a competitive price at $0.0150/1k characters (Pay As You Go) and $0.0135/1k characters (Growth/Enterprise).\n",
      "* **Audio Intelligence**: DeepGram's Summarization model offers a competitive price at $0.0003/1k input tokens - $0.0006/1k output tokens.\n",
      "\n",
      "Please note that this comparison is based on the provided data and might not reflect the full range of pricing options or packages offered by each platform. Additionally, the \"best\" service can depend on various factors such as model performance, accuracy, and specific requirements, which are not considered in this analysis.\n"
     ]
    }
   ],
   "source": [
    "res = genrate_res(prompt=prompt, inp=inp)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = \"\"\"\n",
    "Job Description: AI/ML Engineer (Chatbot, LLM & RAG Specialist)\n",
    "\n",
    "\n",
    "Overview\n",
    "\n",
    " We’re a pioneering startup transforming the UK property market through cutting-edge tools and technologies. Our team is seeking a talented AI/ML Engineer with expertise in Large Language Models (LLM) and Retrieval-Augmented Generation (RAG), to drive innovation and enhance our data-driven solutions. You’ll play a key role in developing AI features like LLM-powered knowledge-based chatbots that empower our users with insightful, accurate information.\n",
    "\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "Design, develop, and deploy AI models, particularly focusing on LLM and RAG, to process and analyse property market data.\n",
    "Collaborate with the development team to integrate AI capabilities into our products, using Python, NestJS, NextJS, React, Azure, and MySQL.\n",
    "Take ownership of the Chatbot service and provide technical recommendations to the software team and business to move in the right direction.\n",
    "Design and implement data extraction and preprocessing pipelines to improve the quality of training data for chatbot models.\n",
    "Continuously monitor and improve the performance of deployed AI services through A/B testing and performance analysis.\n",
    "Lead the exploration and implementation of AI technologies to address industry-specific challenges.\n",
    "Ensure models are scalable, efficient, and seamlessly integrated with our existing tech stack.\n",
    "Stay abreast of AI/ML advancements and propose innovative solutions to enhance our offerings.\n",
    "Provide technical expertise and mentorship to junior team members.\n",
    "Qualifications\n",
    "\n",
    "Bachelor’s or Master’s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n",
    "Proven experience with LLMs and RAG, with a portfolio or projects demonstrating your expertise.\n",
    "Strong programming skills in Python and familiarity with NestJS, NextJS, React, Azure, and MySQL.\n",
    "Ability to translate complex AI/ML concepts into practical solutions.\n",
    "Excellent problem-solving skills and the ability to work in a fast-paced startup environment.\n",
    "A keen interest in the property market and leveraging AI to solve industry challenges.\n",
    "Ability to adapt to a fast-paced, dynamic environment and learn new technologies quickly.\n",
    "\"\"\"\n",
    "\n",
    "inp = \"This is the job desc., by see this tell me the most important topics I should prepare for, and some of the important points, and interview questioins also\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job description, here are the most important topics to prepare for, important points to focus on, and some potential interview questions:\n",
      "\n",
      "**Important topics to prepare:**\n",
      "\n",
      "1. **LLM (Large Language Model) and RAG (Retrieval-Augmented Generation)**: Understand the basics of LLMs, including their architecture, training data, and applications. Familiarize yourself with popular LLMs like BERT, RoBERTa, and XLNet.\n",
      "2. **Chatbot development**: Review the concepts and best practices for building chatbots, such as intent recognition, entity extraction, and dialogue flow management.\n",
      "3. **AI/ML programming**: Be prepared to talk about your experience with Python, NestJS, NextJS, React, Azure, and MySQL.\n",
      "4. **Property market knowledge**: Show your understanding of the property market, its challenges, and how AI can be applied to solve these challenges.\n",
      "5. **Data preprocessing and analysis**: Be prepared to discuss your experience with data preprocessing, data mining, and data analysis, including tools like Pandas, NumPy, and Matplotlib.\n",
      "\n",
      "**Important points to focus on:**\n",
      "\n",
      "1. **Understanding the business problem**: Show that you can understand the business requirements and how AI can be applied to solve the problems in the property market.\n",
      "2. **Technical expertise**: Highlight your programming skills, AI/ML experience, and familiarity with the mentioned technologies.\n",
      "3. **Creativity and innovation**: Be prepared to discuss your ideas for innovative solutions using AI in the property market.\n",
      "4. **Collaboration and communication**: Emphasize your ability to work with the development team, provide technical recommendations, and communicate complex AI/ML concepts to non-technical stakeholders.\n",
      "5. **Continuous learning**: Show your enthusiasm for staying up-to-date with AI/ML advancements and willingness to adapt to new technologies.\n",
      "\n",
      "**Potential interview questions:**\n",
      "\n",
      "1. Can you explain the concept of LLMs and their applications in Chatbots?\n",
      "2. How would you approach building a chatbot for the property market, and what technical skills would you use?\n",
      "3. How do you stay current with advancements in AI/ML, and how do you adapt to new technologies?\n",
      "4. Can you walk me through your experience with Python and other programming languages?\n",
      "5. How would you propose using AI to solve industry-specific challenges in the property market?\n",
      "6. Can you explain the differences between LLMs and RAG, and how they can be used together?\n",
      "7. How do you handle non-typical or high-traffic query volumes in a chatbot?\n",
      "8. Can you describe a project you worked on that leveraged AI/ML, and what was your role in it?\n",
      "9. How do you balance the need for complex AI/ML solutions with the requirement for efficiency and scalability?\n",
      "10. Can you propose an innovative AI-based solution for the property market, and how you would approach implementing it?\n",
      "\n",
      "Remember to review the job description and requirements carefully, and be prepared to provide specific examples from your experience and skills to demonstrate your fit for the role.\n"
     ]
    }
   ],
   "source": [
    "res = genrate_res(prompt=pro, inp=inp)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = \"\"\"\n",
    "\n",
    "Pay-as-you-go (prices in USD)***\n",
    "Rate Limits**\n",
    "\n",
    "360 RPM (requests per minute)\n",
    "\n",
    "10 million TPM (tokens per minute)\n",
    "\n",
    "10,000 RPD (requests per day)\n",
    "\n",
    "Price (input)\n",
    "\n",
    "$0.35 / 1 million tokens (for prompts up to 128K tokens)\n",
    "\n",
    "$0.70 / 1 million tokens (for prompts longer than 128K)\n",
    "\n",
    "Context caching - coming soon\n",
    "\n",
    "Not applicable\n",
    "\n",
    "Price (output)\n",
    "\n",
    "$1.05 / 1 million tokens (for prompts up to 128K tokens)\n",
    "\n",
    "$2.10 / 1 million tokens (for prompts longer than 128K)\n",
    "\n",
    "Prompts/responses used to improve our products\n",
    "\"\"\"\n",
    "\n",
    "inp = \"this is the price rate of gemini-1.5-flash mode. Tell me about the price rate of audio analysis from here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided rate limits and pricing information for the Gemini-1.5 Flash mode, let's assume that the price rate for audio analysis is based on the number of tokens processed.\n",
      "\n",
      "**Audio Analysis Pricing**\n",
      "\n",
      "The price rate for audio analysis seems to be priced based on the number of tokens processed. The price rate is split into two categories:\n",
      "\n",
      "1. **Up to 128K tokens**: $0.35 per 1 million tokens\n",
      "2. **Longer than 128K tokens**: $0.70 per 1 million tokens\n",
      "\n",
      "To estimate the price rate for audio analysis, let's assume that the audio analysis process is token-based, similar to the text-to-text model. In this case, the token is a unit of measurement for the audio data processed.\n",
      "\n",
      "For example, if you process 1 million tokens of audio data, the price would be:\n",
      "\n",
      "* For prompts up to 128K tokens: $0.35 (35 cents) per 1 million tokens\n",
      "* For prompts longer than 128K tokens: $0.70 (70 cents) per 1 million tokens\n",
      "\n",
      "Keep in mind that this is just an estimate based on the provided rate limits and pricing information. The actual pricing for audio analysis may vary depending on the specific requirements and usage of the Gemini-1.5 Flash mode.\n"
     ]
    }
   ],
   "source": [
    "res = genrate_res(prompt=pro, inp=inp)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
